{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-c7BBIO8aSJ",
        "outputId": "6d85743f-87e2-4fa1-b47b-23a1b1adb4b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5okAhOPZ6-OY",
        "outputId": "ba58b089-064a-4df8-b126-059e5e161bb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchinfo torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwoxujYH7LlO",
        "outputId": "062515e8-b0d5-4436-a6b4-21d604c06f66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting monai\n",
            "  Downloading monai-1.4.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.24 in /usr/local/lib/python3.10/dist-packages (from monai) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from monai) (2.5.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.9->monai) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->monai) (3.0.2)\n",
            "Downloading monai-1.4.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: monai\n",
            "Successfully installed monai-1.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install monai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1DO8Wx09ltG",
        "outputId": "320ad7fa-5c66-4678-a81e-6d3be1e75014"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (5.2.1)\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.10/dist-packages (1.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from nibabel) (1.26.4)\n",
            "Requirement already satisfied: packaging>=17 in /usr/local/lib/python3.10/dist-packages (from nibabel) (24.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch nibabel torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIUaKECD7KVF"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple, Union\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from monai.networks.blocks import UnetrBasicBlock, UnetrPrUpBlock, UnetrUpBlock\n",
        "from monai.networks.blocks.dynunet_block import UnetOutBlock\n",
        "from monai.networks.nets import ViT\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0kkneX0848d"
      },
      "source": [
        "##Model: UNET-R"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P6cyWDcU4ohn"
      },
      "outputs": [],
      "source": [
        "class UNETR_Reconstruction(nn.Module):\n",
        "    \"\"\"\n",
        "    Modified UNETR for 3D medical image reconstruction tasks.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        img_size: Tuple[int, int, int],\n",
        "        feature_size: int = 16,\n",
        "        hidden_size: int = 768,\n",
        "        mlp_dim: int = 3072,\n",
        "        num_heads: int = 12,\n",
        "        pos_embed: str = \"perceptron\",\n",
        "        norm_name: Union[Tuple, str] = \"instance\",\n",
        "        conv_block: bool = False,\n",
        "        res_block: bool = True,\n",
        "        dropout_rate: float = 0.0,\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            in_channels: dimension of input channels (e.g., 1 for grayscale MRI).\n",
        "            img_size: dimension of input image.\n",
        "            feature_size: dimension of network feature size.\n",
        "            hidden_size: dimension of hidden layer.\n",
        "            mlp_dim: dimension of feedforward layer.\n",
        "            num_heads: number of attention heads.\n",
        "            pos_embed: position embedding layer type.\n",
        "            norm_name: feature normalization type and arguments.\n",
        "            conv_block: bool argument to determine if convolutional block is used.\n",
        "            res_block: bool argument to determine if residual block is used.\n",
        "            dropout_rate: fraction of the input units to drop.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        if not (0 <= dropout_rate <= 1):\n",
        "            raise AssertionError(\"dropout_rate should be between 0 and 1.\")\n",
        "\n",
        "        if hidden_size % num_heads != 0:\n",
        "            raise AssertionError(\"hidden size should be divisible by num_heads.\")\n",
        "\n",
        "        if pos_embed not in [\"conv\", \"perceptron\"]:\n",
        "            raise KeyError(f\"Position embedding layer of type {pos_embed} is not supported.\")\n",
        "\n",
        "        self.num_layers = 12\n",
        "        self.patch_size = (16, 16, 16)  # UNETR typically uses 16x16x16 patches\n",
        "        self.feat_size = (\n",
        "            img_size[0] // self.patch_size[0],\n",
        "            img_size[1] // self.patch_size[1],\n",
        "            img_size[2] // self.patch_size[2],\n",
        "        )\n",
        "        self.hidden_size = hidden_size\n",
        "        self.classification = False\n",
        "\n",
        "        # Vision Transformer (ViT) backbone\n",
        "        self.vit = ViT(\n",
        "            in_channels=in_channels,\n",
        "            img_size=img_size,\n",
        "            patch_size=self.patch_size,\n",
        "            hidden_size=hidden_size,\n",
        "            mlp_dim=mlp_dim,\n",
        "            num_layers=self.num_layers,\n",
        "            num_heads=num_heads,\n",
        "            classification=self.classification,\n",
        "            dropout_rate=dropout_rate,\n",
        "        )\n",
        "\n",
        "        # Encoder blocks (extract features at different resolutions)\n",
        "        self.encoder1 = UnetrBasicBlock(\n",
        "            spatial_dims=3,\n",
        "            in_channels=in_channels,\n",
        "            out_channels=feature_size,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            norm_name=norm_name,\n",
        "            res_block=res_block,\n",
        "        )\n",
        "        self.encoder2 = UnetrPrUpBlock(\n",
        "            spatial_dims=3,\n",
        "            in_channels=hidden_size,\n",
        "            out_channels=feature_size * 2,\n",
        "            num_layer=2,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            upsample_kernel_size=2,\n",
        "            norm_name=norm_name,\n",
        "            conv_block=conv_block,\n",
        "            res_block=res_block,\n",
        "        )\n",
        "        self.encoder3 = UnetrPrUpBlock(\n",
        "            spatial_dims=3,\n",
        "            in_channels=hidden_size,\n",
        "            out_channels=feature_size * 4,\n",
        "            num_layer=1,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            upsample_kernel_size=2,\n",
        "            norm_name=norm_name,\n",
        "            conv_block=conv_block,\n",
        "            res_block=res_block,\n",
        "        )\n",
        "        self.encoder4 = UnetrPrUpBlock(\n",
        "            spatial_dims=3,\n",
        "            in_channels=hidden_size,\n",
        "            out_channels=feature_size * 8,\n",
        "            num_layer=0,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            upsample_kernel_size=2,\n",
        "            norm_name=norm_name,\n",
        "            conv_block=conv_block,\n",
        "            res_block=res_block,\n",
        "        )\n",
        "\n",
        "        # Decoder blocks (upsample and reconstruct the input)\n",
        "        self.decoder5 = UnetrUpBlock(\n",
        "            spatial_dims=3,\n",
        "            in_channels=hidden_size,\n",
        "            out_channels=feature_size * 8,\n",
        "            kernel_size=3,\n",
        "            upsample_kernel_size=2,\n",
        "            norm_name=norm_name,\n",
        "            res_block=res_block,\n",
        "        )\n",
        "        self.decoder4 = UnetrUpBlock(\n",
        "            spatial_dims=3,\n",
        "            in_channels=feature_size * 8,\n",
        "            out_channels=feature_size * 4,\n",
        "            kernel_size=3,\n",
        "            upsample_kernel_size=2,\n",
        "            norm_name=norm_name,\n",
        "            res_block=res_block,\n",
        "        )\n",
        "        self.decoder3 = UnetrUpBlock(\n",
        "            spatial_dims=3,\n",
        "            in_channels=feature_size * 4,\n",
        "            out_channels=feature_size * 2,\n",
        "            kernel_size=3,\n",
        "            upsample_kernel_size=2,\n",
        "            norm_name=norm_name,\n",
        "            res_block=res_block,\n",
        "        )\n",
        "        self.decoder2 = UnetrUpBlock(\n",
        "            spatial_dims=3,\n",
        "            in_channels=feature_size * 2,\n",
        "            out_channels=feature_size,\n",
        "            kernel_size=3,\n",
        "            upsample_kernel_size=2,\n",
        "            norm_name=norm_name,\n",
        "            res_block=res_block,\n",
        "        )\n",
        "\n",
        "        # Output block (reconstruction output, same size as input)\n",
        "        self.out = nn.Conv3d(feature_size, in_channels, kernel_size=1)  # Reconstruction task requires in_channels output\n",
        "\n",
        "        # Optional sigmoid activation to keep the output between 0 and 1\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def proj_feat(self, x, hidden_size, feat_size):\n",
        "        x = x.view(x.size(0), feat_size[0], feat_size[1], feat_size[2], hidden_size)\n",
        "        x = x.permute(0, 4, 1, 2, 3).contiguous()\n",
        "        return x\n",
        "\n",
        "    def forward(self, x_in):\n",
        "        x, hidden_states_out = self.vit(x_in)\n",
        "        enc1 = self.encoder1(x_in)\n",
        "        x2 = hidden_states_out[3]\n",
        "        enc2 = self.encoder2(self.proj_feat(x2, self.hidden_size, self.feat_size))\n",
        "        x3 = hidden_states_out[6]\n",
        "        enc3 = self.encoder3(self.proj_feat(x3, self.hidden_size, self.feat_size))\n",
        "        x4 = hidden_states_out[9]\n",
        "        enc4 = self.encoder4(self.proj_feat(x4, self.hidden_size, self.feat_size))\n",
        "        dec4 = self.proj_feat(x, self.hidden_size, self.feat_size)\n",
        "        dec3 = self.decoder5(dec4, enc4)\n",
        "        dec2 = self.decoder4(dec3, enc3)\n",
        "        dec1 = self.decoder3(dec2, enc2)\n",
        "        out = self.decoder2(dec1, enc1)\n",
        "        logits = self.out(out)\n",
        "        return self.sigmoid(logits)  # Optionally apply sigmoid activation for normalized output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cpmt3BZn62ng",
        "outputId": "f2936efe-70c5-4fc8-a10b-da96d64dcc44"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "===============================================================================================\n",
              "Layer (type:depth-idx)                        Output Shape              Param #\n",
              "===============================================================================================\n",
              "UNETR_Reconstruction                          [2, 1, 16, 128, 128]      --\n",
              "├─ViT: 1-1                                    [2, 64, 768]              --\n",
              "│    └─PatchEmbeddingBlock: 2-1               [2, 64, 768]              49,152\n",
              "│    │    └─Conv3d: 3-1                       [2, 768, 1, 8, 8]         3,146,496\n",
              "│    │    └─Dropout: 3-2                      [2, 64, 768]              --\n",
              "│    └─ModuleList: 2-2                        --                        --\n",
              "│    │    └─TransformerBlock: 3-3             [2, 64, 768]              9,447,168\n",
              "│    │    └─TransformerBlock: 3-4             [2, 64, 768]              9,447,168\n",
              "│    │    └─TransformerBlock: 3-5             [2, 64, 768]              9,447,168\n",
              "│    │    └─TransformerBlock: 3-6             [2, 64, 768]              9,447,168\n",
              "│    │    └─TransformerBlock: 3-7             [2, 64, 768]              9,447,168\n",
              "│    │    └─TransformerBlock: 3-8             [2, 64, 768]              9,447,168\n",
              "│    │    └─TransformerBlock: 3-9             [2, 64, 768]              9,447,168\n",
              "│    │    └─TransformerBlock: 3-10            [2, 64, 768]              9,447,168\n",
              "│    │    └─TransformerBlock: 3-11            [2, 64, 768]              9,447,168\n",
              "│    │    └─TransformerBlock: 3-12            [2, 64, 768]              9,447,168\n",
              "│    │    └─TransformerBlock: 3-13            [2, 64, 768]              9,447,168\n",
              "│    │    └─TransformerBlock: 3-14            [2, 64, 768]              9,447,168\n",
              "│    └─LayerNorm: 2-3                         [2, 64, 768]              1,536\n",
              "├─UnetrBasicBlock: 1-2                        [2, 32, 16, 128, 128]     --\n",
              "│    └─UnetResBlock: 2-4                      [2, 32, 16, 128, 128]     --\n",
              "│    │    └─Convolution: 3-15                 [2, 32, 16, 128, 128]     864\n",
              "│    │    └─InstanceNorm3d: 3-16              [2, 32, 16, 128, 128]     --\n",
              "│    │    └─LeakyReLU: 3-17                   [2, 32, 16, 128, 128]     --\n",
              "│    │    └─Convolution: 3-18                 [2, 32, 16, 128, 128]     27,648\n",
              "│    │    └─InstanceNorm3d: 3-19              [2, 32, 16, 128, 128]     --\n",
              "│    │    └─Convolution: 3-20                 [2, 32, 16, 128, 128]     32\n",
              "│    │    └─InstanceNorm3d: 3-21              [2, 32, 16, 128, 128]     --\n",
              "│    │    └─LeakyReLU: 3-22                   [2, 32, 16, 128, 128]     --\n",
              "├─UnetrPrUpBlock: 1-3                         [2, 64, 8, 64, 64]        --\n",
              "│    └─Convolution: 2-5                       [2, 64, 2, 16, 16]        --\n",
              "│    │    └─ConvTranspose3d: 3-23             [2, 64, 2, 16, 16]        393,216\n",
              "│    └─ModuleList: 2-6                        --                        --\n",
              "│    │    └─Convolution: 3-24                 [2, 64, 4, 32, 32]        32,768\n",
              "│    │    └─Convolution: 3-25                 [2, 64, 8, 64, 64]        32,768\n",
              "├─UnetrPrUpBlock: 1-4                         [2, 128, 4, 32, 32]       --\n",
              "│    └─Convolution: 2-7                       [2, 128, 2, 16, 16]       --\n",
              "│    │    └─ConvTranspose3d: 3-26             [2, 128, 2, 16, 16]       786,432\n",
              "│    └─ModuleList: 2-8                        --                        --\n",
              "│    │    └─Convolution: 3-27                 [2, 128, 4, 32, 32]       131,072\n",
              "├─UnetrPrUpBlock: 1-5                         [2, 256, 2, 16, 16]       --\n",
              "│    └─Convolution: 2-9                       [2, 256, 2, 16, 16]       --\n",
              "│    │    └─ConvTranspose3d: 3-28             [2, 256, 2, 16, 16]       1,572,864\n",
              "├─UnetrUpBlock: 1-6                           [2, 256, 2, 16, 16]       --\n",
              "│    └─Convolution: 2-10                      [2, 256, 2, 16, 16]       --\n",
              "│    │    └─ConvTranspose3d: 3-29             [2, 256, 2, 16, 16]       1,572,864\n",
              "│    └─UnetResBlock: 2-11                     [2, 256, 2, 16, 16]       --\n",
              "│    │    └─Convolution: 3-30                 [2, 256, 2, 16, 16]       3,538,944\n",
              "│    │    └─InstanceNorm3d: 3-31              [2, 256, 2, 16, 16]       --\n",
              "│    │    └─LeakyReLU: 3-32                   [2, 256, 2, 16, 16]       --\n",
              "│    │    └─Convolution: 3-33                 [2, 256, 2, 16, 16]       1,769,472\n",
              "│    │    └─InstanceNorm3d: 3-34              [2, 256, 2, 16, 16]       --\n",
              "│    │    └─Convolution: 3-35                 [2, 256, 2, 16, 16]       131,072\n",
              "│    │    └─InstanceNorm3d: 3-36              [2, 256, 2, 16, 16]       --\n",
              "│    │    └─LeakyReLU: 3-37                   [2, 256, 2, 16, 16]       --\n",
              "├─UnetrUpBlock: 1-7                           [2, 128, 4, 32, 32]       --\n",
              "│    └─Convolution: 2-12                      [2, 128, 4, 32, 32]       --\n",
              "│    │    └─ConvTranspose3d: 3-38             [2, 128, 4, 32, 32]       262,144\n",
              "│    └─UnetResBlock: 2-13                     [2, 128, 4, 32, 32]       --\n",
              "│    │    └─Convolution: 3-39                 [2, 128, 4, 32, 32]       884,736\n",
              "│    │    └─InstanceNorm3d: 3-40              [2, 128, 4, 32, 32]       --\n",
              "│    │    └─LeakyReLU: 3-41                   [2, 128, 4, 32, 32]       --\n",
              "│    │    └─Convolution: 3-42                 [2, 128, 4, 32, 32]       442,368\n",
              "│    │    └─InstanceNorm3d: 3-43              [2, 128, 4, 32, 32]       --\n",
              "│    │    └─Convolution: 3-44                 [2, 128, 4, 32, 32]       32,768\n",
              "│    │    └─InstanceNorm3d: 3-45              [2, 128, 4, 32, 32]       --\n",
              "│    │    └─LeakyReLU: 3-46                   [2, 128, 4, 32, 32]       --\n",
              "├─UnetrUpBlock: 1-8                           [2, 64, 8, 64, 64]        --\n",
              "│    └─Convolution: 2-14                      [2, 64, 8, 64, 64]        --\n",
              "│    │    └─ConvTranspose3d: 3-47             [2, 64, 8, 64, 64]        65,536\n",
              "│    └─UnetResBlock: 2-15                     [2, 64, 8, 64, 64]        --\n",
              "│    │    └─Convolution: 3-48                 [2, 64, 8, 64, 64]        221,184\n",
              "│    │    └─InstanceNorm3d: 3-49              [2, 64, 8, 64, 64]        --\n",
              "│    │    └─LeakyReLU: 3-50                   [2, 64, 8, 64, 64]        --\n",
              "│    │    └─Convolution: 3-51                 [2, 64, 8, 64, 64]        110,592\n",
              "│    │    └─InstanceNorm3d: 3-52              [2, 64, 8, 64, 64]        --\n",
              "│    │    └─Convolution: 3-53                 [2, 64, 8, 64, 64]        8,192\n",
              "│    │    └─InstanceNorm3d: 3-54              [2, 64, 8, 64, 64]        --\n",
              "│    │    └─LeakyReLU: 3-55                   [2, 64, 8, 64, 64]        --\n",
              "├─UnetrUpBlock: 1-9                           [2, 32, 16, 128, 128]     --\n",
              "│    └─Convolution: 2-16                      [2, 32, 16, 128, 128]     --\n",
              "│    │    └─ConvTranspose3d: 3-56             [2, 32, 16, 128, 128]     16,384\n",
              "│    └─UnetResBlock: 2-17                     [2, 32, 16, 128, 128]     --\n",
              "│    │    └─Convolution: 3-57                 [2, 32, 16, 128, 128]     55,296\n",
              "│    │    └─InstanceNorm3d: 3-58              [2, 32, 16, 128, 128]     --\n",
              "│    │    └─LeakyReLU: 3-59                   [2, 32, 16, 128, 128]     --\n",
              "│    │    └─Convolution: 3-60                 [2, 32, 16, 128, 128]     27,648\n",
              "│    │    └─InstanceNorm3d: 3-61              [2, 32, 16, 128, 128]     --\n",
              "│    │    └─Convolution: 3-62                 [2, 32, 16, 128, 128]     2,048\n",
              "│    │    └─InstanceNorm3d: 3-63              [2, 32, 16, 128, 128]     --\n",
              "│    │    └─LeakyReLU: 3-64                   [2, 32, 16, 128, 128]     --\n",
              "├─Conv3d: 1-10                                [2, 1, 16, 128, 128]      33\n",
              "├─Sigmoid: 1-11                               [2, 1, 16, 128, 128]      --\n",
              "===============================================================================================\n",
              "Total params: 128,682,145\n",
              "Trainable params: 128,682,145\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (G): 122.06\n",
              "===============================================================================================\n",
              "Input size (MB): 2.10\n",
              "Forward/backward pass size (MB): 1275.07\n",
              "Params size (MB): 401.18\n",
              "Estimated Total Size (MB): 1678.34\n",
              "==============================================================================================="
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torchinfo\n",
        "\n",
        "model = UNETR_Reconstruction(in_channels=1, img_size=(16, 128, 128), feature_size=32, norm_name='instance')\n",
        "\n",
        "# batch_size=2, channels=1, depth=16, height=128, width=128\n",
        "torchinfo.summary(model, input_size=(2, 1, 16,  128,  128))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FQXQtMn8-MF"
      },
      "source": [
        "##Dataset : openBHB Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Qxo47CUe9tCv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQkxjkGh8VX_"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to the zip file in your Google Drive\n",
        "zip_file_path = '/content/drive/MyDrive/archive (9).zip'\n",
        "\n",
        "# Destination path to extract files\n",
        "destination_dir = '/content/dataset/'\n",
        "\n",
        "# Unzipping the file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(destination_dir)\n",
        "\n",
        "# List the extracted files (optional)\n",
        "os.listdir(destination_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-YIDSOOG9rOa"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class BrainMRIDataset(Dataset):\n",
        "    def __init__(self, base_path, target_size=(88, 128, 128), slice_depth=16, transform=None):\n",
        "        self.base_path = base_path\n",
        "        self.target_size = target_size  # Target shape should be (128, 128, 128)\n",
        "        self.slice_depth = slice_depth\n",
        "        self.transform = transform\n",
        "\n",
        "        self.subject_ids = self._get_subject_ids()[:500]\n",
        "\n",
        "    def _get_subject_ids(self):\n",
        "        files = os.listdir(self.base_path)\n",
        "\n",
        "        subject_ids = []\n",
        "        for file in files:\n",
        "            if file.endswith('_preproc-quasiraw_T1w.npy'):\n",
        "                subject_id_str = file.split('_')[0].replace('sub-', '')\n",
        "                subject_ids.append(subject_id_str)\n",
        "\n",
        "        return subject_ids\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.subject_ids)\n",
        "\n",
        "    def crop(self, volume, start_y=20, end_y=160, start_x=20, end_x=196, start_z=50, end_z=130):\n",
        "      cropped_volume = volume[ start_z:end_z,start_y:end_y, start_x:end_x]\n",
        "      return cropped_volume\n",
        "\n",
        "    def get_slices(self, mri_volume):\n",
        "        if len(mri_volume.shape) != 3:\n",
        "            mri_volume = mri_volume.squeeze()\n",
        "\n",
        "        patches = []\n",
        "        num_slices = mri_volume.shape[0] // self.slice_depth\n",
        "\n",
        "        for i in range(num_slices):\n",
        "            start = i * self.slice_depth\n",
        "            end = start + self.slice_depth\n",
        "            patch = mri_volume[start:end, :, :]\n",
        "            patches.append(patch)\n",
        "\n",
        "        remainder = mri_volume.shape[0] % self.slice_depth\n",
        "        if remainder > 0:\n",
        "            patch = mri_volume[-self.slice_depth:, :, :]\n",
        "            patches.append(patch)\n",
        "\n",
        "        return patches\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        subject_id = self.subject_ids[index]\n",
        "\n",
        "        # Construct the file path\n",
        "        file_path = f\"{self.base_path}/sub-{subject_id}_preproc-quasiraw_T1w.npy\"\n",
        "\n",
        "        # Load the .npy file\n",
        "        mri_volume = np.load(file_path)  # Shape: (1, 1, 182, 218, 182)\n",
        "\n",
        "        # Convert to tensor and remove redundant dimensions\n",
        "        mri_volume = torch.tensor(mri_volume).float().squeeze().squeeze()  # Shape: [182, 218, 182]\n",
        "\n",
        "        # (C, H, W, D ) - > (C, D, H, W)\n",
        "        mri_volume = mri_volume.permute(2, 0, 1)\n",
        "\n",
        "        #Crop to (80 , 140, 176)\n",
        "        mri_crop = self.crop(mri_volume)\n",
        "\n",
        "        # Resize to target shape (128x128x128)\n",
        "        mri_resize = F.interpolate(\n",
        "            mri_crop.unsqueeze(0).unsqueeze(0),\n",
        "            size=(mri_crop.shape[0], 128, 128),\n",
        "            mode='trilinear',\n",
        "            align_corners=False\n",
        "        ).squeeze()\n",
        "\n",
        "        # Normalize the volume\n",
        "        mri_volume = (mri_resize - mri_resize.min()) / (mri_resize.max() - mri_resize.min() + 1e-8)\n",
        "\n",
        "        # Slice the volume along the depth axis\n",
        "        mri_slices = self.get_slices(mri_volume)\n",
        "\n",
        "        # Add channel dimension back to each slice\n",
        "        mri_slices = [slice.unsqueeze(0) for slice in mri_slices]  # Shape: [1, 128, 128, 8]\n",
        "\n",
        "        return mri_slices\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BY9t-ekM-qMt"
      },
      "outputs": [],
      "source": [
        "# Initialize dataset\n",
        "dataset = BrainMRIDataset(base_path='/content/dataset/val_quasiraw')\n",
        "\n",
        "# Test the dataset\n",
        "volume_slices = dataset[0]\n",
        "print(f\"Number of slices: {len(volume_slices)}, Slice shape: {volume_slices[0].shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0lYZ4hb-6u0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "class SliceDatasetFromList(Dataset):\n",
        "    def __init__(self, patch_list):\n",
        "        # Flatten the list of lists into a single list\n",
        "        self.patch_list = [patch for sublist in patch_list for patch in sublist]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.patch_list)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        patch = self.patch_list[index]\n",
        "        patch_tensor = torch.tensor(patch).float()  # Convert each patch to tensor\n",
        "\n",
        "        # For simplicity, we return the patch as both input and target (autoencoder-like task)\n",
        "        return patch_tensor, patch_tensor\n",
        "\n",
        "\n",
        "# Initialize the dataset\n",
        "Slices = SliceDatasetFromList(dataset)\n",
        "\n",
        "# Define train, validation, and test split ratios\n",
        "train_ratio = 0.7\n",
        "val_ratio = 0.15\n",
        "test_ratio = 0.15\n",
        "\n",
        "# Calculate the sizes for each split\n",
        "train_size = int(train_ratio * len(Slices))\n",
        "val_size = int(val_ratio * len(Slices))\n",
        "test_size = len(Slices) - train_size - val_size\n",
        "\n",
        "# Perform the random split\n",
        "train_dataset, val_dataset, test_dataset = random_split(Slices, [train_size, val_size, test_size])\n",
        "\n",
        "# Initialize DataLoaders for each split\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=False)\n",
        "\n",
        "# Print the sizes of each dataset split\n",
        "print(\"Train set size:\", len(train_dataset))\n",
        "print(\"Validation set size:\", len(val_dataset))\n",
        "print(\"Test set size:\", len(test_dataset))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0QOWwKNCRAx"
      },
      "source": [
        "##Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnQorWJACwO1"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTG1pEAtCQX2"
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.MSELoss()  # Mean Squared Error for reconstruction\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQI11K6pBBjB"
      },
      "outputs": [],
      "source": [
        "# Check if GPU is available and set the device accordingly\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGI1jsh5B6BQ"
      },
      "outputs": [],
      "source": [
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdqtNiiGB8Hf"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(state, is_best, checkpoint_dir=\"/content/drive/MyDrive/checkpoint_unetr_2\", filename=\"checkpoint.pth\"):\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "    checkpoint_path = os.path.join(checkpoint_dir, filename)\n",
        "    torch.save(state, checkpoint_path)\n",
        "    if is_best:\n",
        "        best_model_path = os.path.join(checkpoint_dir, \"best_model.pth\")\n",
        "        torch.save(state, best_model_path)\n",
        "        print(f\"Best model saved to {best_model_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8gtnoamtDR0Y",
        "outputId": "4ca00f35-16ae-4d9b-9b33-6fbd2da77b97"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/50 (Training):   0%|          | 0/287 [00:00<?, ?it/s]<ipython-input-35-485e569ed15f>:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  patch_tensor = torch.tensor(patch).float()\n",
            "Epoch 1/50 (Training): 100%|██████████| 287/287 [03:38<00:00,  1.31it/s]\n",
            "Epoch 1/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/50], Train Loss: 0.5256, Val Loss: 0.4519\n",
            "Best model saved to /content/drive/MyDrive/checkpoint_UNET/best_model_MSE_SSIM.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/50 (Training): 100%|██████████| 287/287 [03:41<00:00,  1.30it/s]\n",
            "Epoch 2/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/50], Train Loss: 0.3557, Val Loss: 0.2615\n",
            "Best model saved to /content/drive/MyDrive/checkpoint_UNET/best_model_MSE_SSIM.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/50 (Training): 100%|██████████| 287/287 [03:40<00:00,  1.30it/s]\n",
            "Epoch 3/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/50], Train Loss: 0.1733, Val Loss: 0.1502\n",
            "Best model saved to /content/drive/MyDrive/checkpoint_UNET/best_model_MSE_SSIM.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/50 (Training): 100%|██████████| 287/287 [03:40<00:00,  1.30it/s]\n",
            "Epoch 4/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/50], Train Loss: 0.1142, Val Loss: 0.0865\n",
            "Best model saved to /content/drive/MyDrive/checkpoint_UNET/best_model_MSE_SSIM.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/50 (Training): 100%|██████████| 287/287 [03:40<00:00,  1.30it/s]\n",
            "Epoch 5/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/50], Train Loss: 0.1021, Val Loss: 0.1027\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/50 (Training): 100%|██████████| 287/287 [03:40<00:00,  1.30it/s]\n",
            "Epoch 6/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/50], Train Loss: 0.0903, Val Loss: 0.0660\n",
            "Best model saved to /content/drive/MyDrive/checkpoint_UNET/best_model_MSE_SSIM.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/50 (Training): 100%|██████████| 287/287 [03:40<00:00,  1.30it/s]\n",
            "Epoch 7/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.22it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/50], Train Loss: 0.0725, Val Loss: 0.0540\n",
            "Best model saved to /content/drive/MyDrive/checkpoint_UNET/best_model_MSE_SSIM.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/50 (Training): 100%|██████████| 287/287 [03:40<00:00,  1.30it/s]\n",
            "Epoch 8/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/50], Train Loss: 0.0619, Val Loss: 0.0501\n",
            "Best model saved to /content/drive/MyDrive/checkpoint_UNET/best_model_MSE_SSIM.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/50 (Training): 100%|██████████| 287/287 [03:40<00:00,  1.30it/s]\n",
            "Epoch 9/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [9/50], Train Loss: 0.0530, Val Loss: 0.0387\n",
            "Best model saved to /content/drive/MyDrive/checkpoint_UNET/best_model_MSE_SSIM.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/50 (Training): 100%|██████████| 287/287 [03:40<00:00,  1.30it/s]\n",
            "Epoch 10/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/50], Train Loss: 0.0482, Val Loss: 0.0372\n",
            "Best model saved to /content/drive/MyDrive/checkpoint_UNET/best_model_MSE_SSIM.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/50 (Training): 100%|██████████| 287/287 [03:40<00:00,  1.30it/s]\n",
            "Epoch 11/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [11/50], Train Loss: 0.0642, Val Loss: 0.0435\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12/50 (Training): 100%|██████████| 287/287 [03:40<00:00,  1.30it/s]\n",
            "Epoch 12/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [12/50], Train Loss: 0.0490, Val Loss: 0.0342\n",
            "Best model saved to /content/drive/MyDrive/checkpoint_UNET/best_model_MSE_SSIM.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 13/50 (Training): 100%|██████████| 287/287 [03:40<00:00,  1.30it/s]\n",
            "Epoch 13/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [13/50], Train Loss: 0.0425, Val Loss: 0.0298\n",
            "Best model saved to /content/drive/MyDrive/checkpoint_UNET/best_model_MSE_SSIM.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 14/50 (Training): 100%|██████████| 287/287 [03:40<00:00,  1.30it/s]\n",
            "Epoch 14/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [14/50], Train Loss: 0.0403, Val Loss: 0.0293\n",
            "Best model saved to /content/drive/MyDrive/checkpoint_UNET/best_model_MSE_SSIM.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 15/50 (Training): 100%|██████████| 287/287 [03:40<00:00,  1.30it/s]\n",
            "Epoch 15/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [15/50], Train Loss: 0.0357, Val Loss: 0.0263\n",
            "Best model saved to /content/drive/MyDrive/checkpoint_UNET/best_model_MSE_SSIM.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 16/50 (Training): 100%|██████████| 287/287 [03:40<00:00,  1.30it/s]\n",
            "Epoch 16/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [16/50], Train Loss: 0.0325, Val Loss: 0.0238\n",
            "Best model saved to /content/drive/MyDrive/checkpoint_UNET/best_model_MSE_SSIM.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 17/50 (Training): 100%|██████████| 287/287 [03:40<00:00,  1.30it/s]\n",
            "Epoch 17/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [17/50], Train Loss: 0.0310, Val Loss: 0.0241\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 18/50 (Training): 100%|██████████| 287/287 [03:40<00:00,  1.30it/s]\n",
            "Epoch 18/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [18/50], Train Loss: 0.0290, Val Loss: 0.0216\n",
            "Best model saved to /content/drive/MyDrive/checkpoint_UNET/best_model_MSE_SSIM.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 19/50 (Training): 100%|██████████| 287/287 [03:40<00:00,  1.30it/s]\n",
            "Epoch 19/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [19/50], Train Loss: 0.0268, Val Loss: 0.0211\n",
            "Best model saved to /content/drive/MyDrive/checkpoint_UNET/best_model_MSE_SSIM.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 20/50 (Training): 100%|██████████| 287/287 [03:40<00:00,  1.30it/s]\n",
            "Epoch 20/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [20/50], Train Loss: 0.0261, Val Loss: 0.0191\n",
            "Best model saved to /content/drive/MyDrive/checkpoint_UNET/best_model_MSE_SSIM.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 21/50 (Training): 100%|██████████| 287/287 [03:40<00:00,  1.30it/s]\n",
            "Epoch 21/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [21/50], Train Loss: 0.0266, Val Loss: 0.0176\n",
            "Best model saved to /content/drive/MyDrive/checkpoint_UNET/best_model_MSE_SSIM.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 22/50 (Training): 100%|██████████| 287/287 [03:40<00:00,  1.30it/s]\n",
            "Epoch 22/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [22/50], Train Loss: 0.0234, Val Loss: 0.0203\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 23/50 (Training): 100%|██████████| 287/287 [03:40<00:00,  1.30it/s]\n",
            "Epoch 23/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [23/50], Train Loss: 0.0222, Val Loss: 0.0154\n",
            "Best model saved to /content/drive/MyDrive/checkpoint_UNET/best_model_MSE_SSIM.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 24/50 (Training): 100%|██████████| 287/287 [03:40<00:00,  1.30it/s]\n",
            "Epoch 24/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [24/50], Train Loss: 0.0227, Val Loss: 0.0167\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 25/50 (Training): 100%|██████████| 287/287 [03:40<00:00,  1.30it/s]\n",
            "Epoch 25/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [25/50], Train Loss: 0.0200, Val Loss: 0.0149\n",
            "Best model saved to /content/drive/MyDrive/checkpoint_UNET/best_model_MSE_SSIM.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 26/50 (Training): 100%|██████████| 287/287 [03:40<00:00,  1.30it/s]\n",
            "Epoch 26/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [26/50], Train Loss: 0.0217, Val Loss: 0.0165\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 27/50 (Training): 100%|██████████| 287/287 [03:40<00:00,  1.30it/s]\n",
            "Epoch 27/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [27/50], Train Loss: 0.0187, Val Loss: 0.0157\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 28/50 (Training): 100%|██████████| 287/287 [03:40<00:00,  1.30it/s]\n",
            "Epoch 28/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [28/50], Train Loss: 0.0176, Val Loss: 0.0128\n",
            "Best model saved to /content/drive/MyDrive/checkpoint_UNET/best_model_MSE_SSIM.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 29/50 (Training): 100%|██████████| 287/287 [03:40<00:00,  1.30it/s]\n",
            "Epoch 29/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [29/50], Train Loss: 0.0262, Val Loss: 0.0158\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 30/50 (Training): 100%|██████████| 287/287 [03:40<00:00,  1.30it/s]\n",
            "Epoch 30/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [30/50], Train Loss: 0.0183, Val Loss: 0.0127\n",
            "Best model saved to /content/drive/MyDrive/checkpoint_UNET/best_model_MSE_SSIM.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 31/50 (Training): 100%|██████████| 287/287 [03:40<00:00,  1.30it/s]\n",
            "Epoch 31/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [31/50], Train Loss: 0.0191, Val Loss: 0.0127\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 32/50 (Training): 100%|██████████| 287/287 [03:40<00:00,  1.30it/s]\n",
            "Epoch 32/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [32/50], Train Loss: 0.0167, Val Loss: 0.0118\n",
            "Best model saved to /content/drive/MyDrive/checkpoint_UNET/best_model_MSE_SSIM.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 33/50 (Training): 100%|██████████| 287/287 [03:40<00:00,  1.30it/s]\n",
            "Epoch 33/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [33/50], Train Loss: 0.0228, Val Loss: 0.0159\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 34/50 (Training): 100%|██████████| 287/287 [03:40<00:00,  1.30it/s]\n",
            "Epoch 34/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [34/50], Train Loss: 0.0182, Val Loss: 0.0118\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 35/50 (Training): 100%|██████████| 287/287 [03:40<00:00,  1.30it/s]\n",
            "Epoch 35/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [35/50], Train Loss: 0.0170, Val Loss: 0.0112\n",
            "Best model saved to /content/drive/MyDrive/checkpoint_UNET/best_model_MSE_SSIM.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 36/50 (Training): 100%|██████████| 287/287 [03:40<00:00,  1.30it/s]\n",
            "Epoch 36/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.39it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [36/50], Train Loss: 0.0150, Val Loss: 0.0112\n",
            "Best model saved to /content/drive/MyDrive/checkpoint_UNET/best_model_MSE_SSIM.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 37/50 (Training): 100%|██████████| 287/287 [03:40<00:00,  1.30it/s]\n",
            "Epoch 37/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [37/50], Train Loss: 0.0145, Val Loss: 0.0105\n",
            "Best model saved to /content/drive/MyDrive/checkpoint_UNET/best_model_MSE_SSIM.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 38/50 (Training): 100%|██████████| 287/287 [03:40<00:00,  1.30it/s]\n",
            "Epoch 38/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [38/50], Train Loss: 0.0149, Val Loss: 0.0123\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 39/50 (Training): 100%|██████████| 287/287 [03:40<00:00,  1.30it/s]\n",
            "Epoch 39/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [39/50], Train Loss: 0.0144, Val Loss: 0.0105\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 40/50 (Training): 100%|██████████| 287/287 [03:40<00:00,  1.30it/s]\n",
            "Epoch 40/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [40/50], Train Loss: 0.0139, Val Loss: 0.0106\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 41/50 (Training): 100%|██████████| 287/287 [03:40<00:00,  1.30it/s]\n",
            "Epoch 41/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [41/50], Train Loss: 0.0131, Val Loss: 0.0099\n",
            "Best model saved to /content/drive/MyDrive/checkpoint_UNET/best_model_MSE_SSIM.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 42/50 (Training): 100%|██████████| 287/287 [03:41<00:00,  1.30it/s]\n",
            "Epoch 42/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.40it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [42/50], Train Loss: 0.0134, Val Loss: 0.0098\n",
            "Best model saved to /content/drive/MyDrive/checkpoint_UNET/best_model_MSE_SSIM.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 43/50 (Training): 100%|██████████| 287/287 [03:40<00:00,  1.30it/s]\n",
            "Epoch 43/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [43/50], Train Loss: 0.0134, Val Loss: 0.0091\n",
            "Best model saved to /content/drive/MyDrive/checkpoint_UNET/best_model_MSE_SSIM.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 44/50 (Training): 100%|██████████| 287/287 [03:40<00:00,  1.30it/s]\n",
            "Epoch 44/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [44/50], Train Loss: 0.0151, Val Loss: 0.0114\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 45/50 (Training): 100%|██████████| 287/287 [03:40<00:00,  1.30it/s]\n",
            "Epoch 45/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [45/50], Train Loss: 0.0130, Val Loss: 0.0098\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 46/50 (Training): 100%|██████████| 287/287 [03:40<00:00,  1.30it/s]\n",
            "Epoch 46/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [46/50], Train Loss: 0.0130, Val Loss: 0.0084\n",
            "Best model saved to /content/drive/MyDrive/checkpoint_UNET/best_model_MSE_SSIM.pth\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 47/50 (Training): 100%|██████████| 287/287 [03:40<00:00,  1.30it/s]\n",
            "Epoch 47/50 (Validation): 100%|██████████| 51/51 [00:04<00:00, 12.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [47/50], Train Loss: 0.0169, Val Loss: 0.0125\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 48/50 (Training):  87%|████████▋ | 249/287 [03:11<00:29,  1.30it/s]"
          ]
        }
      ],
      "source": [
        "train_loss_values = []\n",
        "val_loss_values = []\n",
        "\n",
        "num_epochs = 200\n",
        "best_val_loss = float('inf')\n",
        "patience = 10\n",
        "early_stop_counter = 0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "\n",
        "    # Training loop\n",
        "    for imgs, targets in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} (Training)'):\n",
        "        imgs, targets = imgs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()  # Clear gradients\n",
        "        outputs = model(imgs)  # Forward pass\n",
        "        loss = criterion(outputs, targets)  # Compute loss\n",
        "        loss.backward()  # Backward pass\n",
        "        optimizer.step()  # Update weights\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    # Average training loss for this epoch\n",
        "    train_loss /= len(train_loader)\n",
        "    train_loss_values.append(train_loss)\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for imgs, targets in tqdm(val_loader, desc=f'Epoch {epoch+1}/{num_epochs} (Validation)'):\n",
        "            imgs, targets = imgs.to(device), targets.to(device)\n",
        "            outputs = model(imgs)  # Forward pass\n",
        "            loss = criterion(outputs, targets)  # Compute validation loss\n",
        "            val_loss += loss.item()  # Accumulate validation loss\n",
        "\n",
        "    # Average validation loss for this epoch\n",
        "    val_loss /= len(val_loader)\n",
        "    val_loss_values.append(val_loss)\n",
        "\n",
        "    # Print the losses for this epoch\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "    is_best = val_loss < best_val_loss\n",
        "    if is_best:\n",
        "        best_val_loss = val_loss\n",
        "        early_stop_counter = 0\n",
        "\n",
        "        # Save the best model checkpoint\n",
        "        checkpoint = {\n",
        "            'epoch': epoch + 1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'train_loss': train_loss,\n",
        "            'val_loss': val_loss\n",
        "        }\n",
        "        save_checkpoint(checkpoint, is_best)\n",
        "    else:\n",
        "        early_stop_counter += 1\n",
        "\n",
        "    # Early stopping condition\n",
        "    if early_stop_counter >= patience:\n",
        "        print(f\"Early stopping at epoch {epoch+1}. No improvement in validation loss for {patience} consecutive epochs.\")\n",
        "        break\n",
        "\n",
        "# Print the best accuracy:\n",
        "print(f\"Best Validation Loss: {best_val_loss:.4f}\")\n",
        "\n",
        "# Plotting the loss\n",
        "clear_output(wait=True)\n",
        "plt.plot(train_loss_values, label='Training Loss')\n",
        "plt.plot(val_loss_values, label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss Over Epochs')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}